{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "For Part A, you need to scrape IMDB web page to find out top movies sorted by user votes. For each movie, you need to pull :\n",
    "- movie_id\n",
    "- rank\n",
    "- title \n",
    "- year\n",
    "- rating\n",
    "- runtime\n",
    "- votes \n",
    "\n",
    "The URL of an page that include movies released between 2018 and 2021 sorted by number of votes is: \n",
    "\n",
    "https://www.imdb.com/search/title/?at=0&sort=num_votes,desc&start=1&title_type=feature&year=2018,2020\n",
    "\n",
    "\n",
    "Please click the URL and investigate how you can pull movie_id, rank, title,... from the webpage. This webpage, however, only includes 50 movies. Hence, if you want to extract top 250 movies between 2018 and 2020 according to  the number of votes, you need to click “next” 4 times and parse 4 more pages. Fortunately, we can do this by modifying the URL a little. For example, the URL\n",
    "\n",
    "https://www.imdb.com/search/title/?at=0&sort=num_votes,desc&start=51&title_type=feature&year=2018,2020\n",
    "\n",
    "(Note that start = 1 in the first URL, now start = 51) allows us to move on to the next page. Obviously, https://www.imdb.com/search/title/?at=0&sort=num_votes,desc&start=101&title_type=feature&year=2018,2020\n",
    "will lead us to the third page. \n",
    "\n",
    "\n",
    "**You need to write code where I have <span style=\"color:red\">'''  Your code here ...    '''.</span>**\n",
    "\n",
    "***\n",
    "Now let’s look at each function in detail. The parameter “top_number” in the function read_m_by_voting(first_year, last_year, top_number)  represents the top number of movies you want to retrieve. For example, read_m_by_voting(2018,2020,500) means that we want to extract top 500 movies released between 2018 and 2020, sorted by users' votes.\n",
    "\n",
    "This function returns a list of dictionaries. Each dictionary represents one of the top movies, which could look like the following:\n",
    "\n",
    "{   \n",
    "   \n",
    "      'movie_id': 'tt6324278',\n",
    "      'title': 'Abominable',\n",
    "      'year': '(2019)',\n",
    "      'rank': '358.', \n",
    "      'runtime': '97 min', \n",
    "      'rating': '7.0', \n",
    "      'votes': '34,093'\n",
    "}\n",
    "\n",
    "In order to implement this function read_m_by_voting(first_year, last_year, top_number), you need to first implement the function read_m_from_url(url, num_of_m=50). This read_m_from_url function is used to extract num_of_m number of movies from a URL. It will also return a list of dictionaries, each of which represents a movie. As described above, to extract say top 120 movies, you need to parse 3 webpage because each page includes only 50 movies. This read_m_from_url function allows you to extract a specific number of movies from a URL. \n",
    "\n",
    "After you implement “read_m_by_voting”, which will return a list of top movies, you need to implement the function write_movies_csv(final_list, filename) to write the movies list to a csv file.\n",
    "\n",
    "***\n",
    "You probably want to first work on read_m_from_url, then read_m_by_voting, and then write_movies_csv. For each of the functions, I included a test function. For instance, for the function, read_m_from_url, I have included a test function called test_read_m_from_url(). Please un-comment the test function to test your code. The test function test_write_movies_csv () outputs \"IMDb_TopVoted.csv\". You need to test each function before moving onto the next. Even within a function, you may need to use print() to test your code very carefully.\n",
    "\n",
    "***\n",
    "\n",
    "After you done with scraping the needed data, you should clean and transform it as needed to make it ready for enriching the given \"Movies.csv\" dataset.\n",
    "\n",
    "Finaly, export the enriched dataset to a CSV file:\n",
    "Use the following naming convention: Project_3_PartA_Lastname.csv\n",
    "\n",
    "\n",
    "\n",
    "### Helper functions\n",
    "***\n",
    "\n",
    "The helper functions section includes some functions you need to use when implementing the three functions describe above. This inculdes the implementation of two functions and test function for each helper function: read_html(url), test_read_html(), process_str_with_comma(string), and test_process_str_with_comma(). For instance, running  test_process_str_with_comma() will help you understand what the function process_str_with_comma(string) does.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The read_html(url) return the contents of an URL hmtl file as a string.\n",
    "\"\"\"\n",
    "def read_html(url):\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    return content\n",
    "\n",
    "#===========================================================================\n",
    "\n",
    "\"\"\"\n",
    "If a string contains comma, use \"\" to enclose the string to write it to a comma-separated values (CSV) \n",
    "file with no issue with the comma.\n",
    "\"\"\"\n",
    "def process_str_with_comma(string):\n",
    "    if ',' in string:\n",
    "        new_string = '\"' + string.strip() + '\"'\n",
    "    else:\n",
    "        new_string = string\n",
    "    return new_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test  read_html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_html():\n",
    "    print (read_html('https://www.imdb.com/search/title/?at=0&sort=num_votes,desc&start=1&title_type=feature&year=2018,2020'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_read_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test  process_str_with_comma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_process_str_with_comma():\n",
    "    \"\"\"output:\n",
    "    string: it is a string\n",
    "    string: \"it is a string, right\"\n",
    "    \"\"\"\n",
    "    string = 'it is a string'\n",
    "    print (\"string: \" + process_str_with_comma(string))\n",
    "    string = 'it is a string, right'\n",
    "    print (\"string: \" + process_str_with_comma(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_process_str_with_comma()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## read_m_from_url\n",
    "\n",
    "Inside this function, you need to write your code to pull the movies information.\n",
    "For each movie, you need to pull :\n",
    "- movie_id\n",
    "- title \n",
    "- rank\n",
    "- year\n",
    "- rating\n",
    "- runtime\n",
    "- votes \n",
    "\n",
    "To give examples on how to pull data from web bage, I have included the code to pull the movie_id, title, and votes.\n",
    "You need to inculde your code to pull the other needed movie information (rank, year, ......). You should have no missing values for each of the collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_m_from_url(url, num_of_m=50):\n",
    "    print(url)\n",
    "    # this function, read a number of movies from a url. The default value is 50\n",
    "    \n",
    "    html_string = read_html(url) # given a url you need to read the hmtl file as a string. \n",
    "    # I have included  the read_html function in the helper functions. Please take a look.\n",
    "    \n",
    "    # create a soup object\n",
    "    soup = BeautifulSoup(html_string, \"html.parser\")\n",
    "    \n",
    "    '''\n",
    "    Click the URL and investigate how you can pull movie_id, rank, title,... from the webpage.\n",
    "    \n",
    "    To investigate the html of a web page , For example:\n",
    "    URL: https://www.imdb.com/search/title/?at=0&sort=num_votes,desc&start=1&title_type=feature&year=2018,2020\n",
    "    Right-click anywhere on the webpage, and at the very bottom of the menu that pops up, \n",
    "    you will see \"Inspect\", Click on it.\n",
    "    '''\n",
    "    \n",
    "# Fetching a div that includes all the movies. This can be done by using find and find_all functions.\n",
    "    # for example, find_all('div') will give you all divs on the page. Actually, \n",
    "    # this find or find_all function can have two parameters,\n",
    "    # in the code below 'div' is the tag name and 'lister-list' is an attribute value of the tag. You can also do\n",
    "    # movie_list = soup.find('div', 'lister-list'). Here you explicitly say: I want to find a div with \n",
    "    # attribute class = 'lister-list'.\n",
    "    \n",
    "    # Since on each imdb page, there's only one div with class = 'lister-list', we can use find rather than find_all. \n",
    "    # Find_all will return a list of div tags, while find() will return only one div.\n",
    "    \n",
    "    movie_list = soup.find('div', 'lister-list') # this div contains all the listed movies in \n",
    "                                                 # the requested html web page.\n",
    "    \n",
    "    list_movies = [] # initialize the function return value, which is a list of movies. \n",
    "                     # This list will contains the scraped data transformed to a structured format.\n",
    "    \n",
    "    # Using count track the number of movies processed. now it's 0 - No movie has been processed yet.\n",
    "    count = 0\n",
    "    \n",
    "    # each movie listed in a div with attribute value 'lister-item mode-advanced'.\n",
    "    divs=  movie_list.find_all('div','lister-item mode-advanced') # To find all the listed movies in the page.\n",
    "    for d in divs:\n",
    "        dict_each_movie = {}  # initialize the movie dictionary to store the movie information.\n",
    "\n",
    "        # Pulling the movie_id\n",
    "        try:\n",
    "            h = d.find('h3','lister-item-header') \n",
    "            movie_id= h.find('a').attrs['href']\n",
    "            movie_id= movie_id[7:-1]\n",
    "            \n",
    "        except:\n",
    "            movie_id=\"\"\n",
    "        finally:\n",
    "            dict_each_movie[\"movie_id\"] = movie_id\n",
    "            print(movie_id)\n",
    "            \n",
    "            \n",
    "\n",
    "        # Pulling the title\n",
    "        try:\n",
    "            h = d.find('h3','lister-item-header') \n",
    "            title= h.find('a').text\n",
    "        except:\n",
    "            title=\"\"\n",
    "        finally:\n",
    "            dict_each_movie[\"title\"] = title\n",
    "            print(title)\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Pulling the rank\n",
    "        '''  Your code here ...    '''\n",
    "\n",
    "        \n",
    "        \n",
    "        # Pulling the year\n",
    "        '''  Your code here ...    '''\n",
    "\n",
    "\n",
    "            \n",
    "        # Pulling the runtime\n",
    "        '''  Your code here ...    '''\n",
    "\n",
    "\n",
    "        \n",
    "        # Pulling the rating\n",
    "        '''  Your code here ...    '''\n",
    "\n",
    "\n",
    "            \n",
    "        # Pulling the votes\n",
    "        try: \n",
    "            div1= d.find('div','lister-item-content')\n",
    "            votes= div1.find('span', text='Votes:').find_next('span').text\n",
    "        except:\n",
    "            votes = \"\"\n",
    "        finally:\n",
    "            dict_each_movie[\"votes\"] = votes\n",
    "            print(votes)\n",
    "\n",
    "\n",
    "        list_movies.append(dict_each_movie)  # To add the movie information to the movies list.\n",
    "\n",
    "        count +=1\n",
    "        print('===============================')\n",
    "        print()\n",
    "        if count == num_of_m:\n",
    "            break # to exit from the loop.\n",
    "\n",
    "    return list_movies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test  read_m_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_read_m_from_url():\n",
    "    \"\"\" output:\n",
    "    [{'movie_id': 'tt7286456', 'title': 'Joker', 'year': '(2019)', 'rank': '1.', 'runtime': '122 min', 'rating': '8.4', 'votes': '1,074,230'}, {'movie_id': 'tt4154796', 'title': 'Avengers: Endgame', 'year': '(2019)', 'rank': '2.', 'runtime': '181 min', 'rating': '8.4', 'votes': '945,461'}, {'movie_id': 'tt4154756', 'title': 'Avengers: Infinity War', 'year': '(2018)', 'rank': '3.', 'runtime': '149 min', 'rating': '8.4', 'votes': '928,596'}, {'movie_id': 'tt1825683', 'title': 'Black Panther', 'year': '(2018)', 'rank': '4.', 'runtime': '134 min', 'rating': '7.3', 'votes': '678,964'}, {'movie_id': 'tt6751668', 'title': 'Parasite', 'year': '(2019)', 'rank': '5.', 'runtime': '132 min', 'rating': '8.6', 'votes': '666,646'}, {'movie_id': 'tt7131622', 'title': 'Once Upon a Time... In Hollywood', 'year': '(2019)', 'rank': '6.', 'runtime': '161 min', 'rating': '7.6', 'votes': '642,048'}, {'movie_id': 'tt8946378', 'title': 'Knives Out', 'year': '(2019)', 'rank': '7.', 'runtime': '130 min', 'rating': '7.9', 'votes': '534,299'}, {'movie_id': 'tt5463162', 'title': 'Deadpool 2', 'year': '(2018)', 'rank': '8.', 'runtime': '119 min', 'rating': '7.7', 'votes': '519,760'}, {'movie_id': 'tt8579674', 'title': '1917', 'year': '(2019)', 'rank': '9.', 'runtime': '119 min', 'rating': '8.3', 'votes': '495,380'}, {'movie_id': 'tt4154664', 'title': 'Captain Marvel', 'year': '(2019)', 'rank': '10.', 'runtime': '123 min', 'rating': '6.8', 'votes': '493,817'}, {'movie_id': 'tt1727824', 'title': 'Bohemian Rhapsody', 'year': '(2018)', 'rank': '11.', 'runtime': '134 min', 'rating': '7.9', 'votes': '489,064'}, {'movie_id': 'tt6644200', 'title': 'A Quiet Place', 'year': '(2018)', 'rank': '12.', 'runtime': '90 min', 'rating': '7.5', 'votes': '482,141'}, {'movie_id': 'tt4633694', 'title': 'Spider-Man: Into the Spider-Verse', 'year': '(2018)', 'rank': '13.', 'runtime': '117 min', 'rating': '8.4', 'votes': '430,153'}, {'movie_id': 'tt6966692', 'title': 'Green Book', 'year': '(2018)', 'rank': '14.', 'runtime': '130 min', 'rating': '8.2', 'votes': '428,762'}, {'movie_id': 'tt6723592', 'title': 'Tenet', 'year': '(2020)', 'rank': '15.', 'runtime': '150 min', 'rating': '7.4', 'votes': '426,125'}, {'movie_id': 'tt1477834', 'title': 'Aquaman', 'year': '(2018)', 'rank': '16.', 'runtime': '143 min', 'rating': '6.9', 'votes': '417,286'}, {'movie_id': 'tt1270797', 'title': 'Venom', 'year': '(2018)', 'rank': '17.', 'runtime': '112 min', 'rating': '6.7', 'votes': '410,565'}, {'movie_id': 'tt2527338', 'title': 'Star Wars: The Rise Of Skywalker', 'year': '(2019)', 'rank': '18.', 'runtime': '141 min', 'rating': '6.5', 'votes': '404,527'}, {'movie_id': 'tt1677720', 'title': 'Ready Player One', 'year': '(2018)', 'rank': '19.', 'runtime': '140 min', 'rating': '7.4', 'votes': '398,599'}, {'movie_id': 'tt6320628', 'title': 'Spider-Man: Far from Home', 'year': '(2019)', 'rank': '20.', 'runtime': '129 min', 'rating': '7.4', 'votes': '383,087'}, {'movie_id': 'tt1517451', 'title': 'A Star Is Born', 'year': '(2018)', 'rank': '21.', 'runtime': '136 min', 'rating': '7.6', 'votes': '356,745'}, {'movie_id': 'tt1302006', 'title': 'The Irishman', 'year': '(2019)', 'rank': '22.', 'runtime': '209 min', 'rating': '7.8', 'votes': '352,691'}, {'movie_id': 'tt5095030', 'title': 'Ant-Man and the Wasp', 'year': '(2018)', 'rank': '23.', 'runtime': '118 min', 'rating': '7.0', 'votes': '346,822'}, {'movie_id': 'tt2584384', 'title': 'Jojo Rabbit', 'year': '(2019)', 'rank': '24.', 'runtime': '108 min', 'rating': '7.9', 'votes': '340,733'}, {'movie_id': 'tt1950186', 'title': 'Ford v Ferrari', 'year': '(2019)', 'rank': '25.', 'runtime': '152 min', 'rating': '8.1', 'votes': '337,490'}, {'movie_id': 'tt3778644', 'title': 'Solo: A Star Wars Story', 'year': '(2018)', 'rank': '26.', 'runtime': '135 min', 'rating': '6.9', 'votes': '313,683'}, {'movie_id': 'tt4912910', 'title': 'Mission: Impossible - Fallout', 'year': '(2018)', 'rank': '27.', 'runtime': '147 min', 'rating': '7.7', 'votes': '308,761'}, {'movie_id': 'tt6146586', 'title': 'John Wick: Chapter 3 - Parabellum', 'year': '(2019)', 'rank': '28.', 'runtime': '130 min', 'rating': '7.4', 'votes': '306,871'}, {'movie_id': 'tt2737304', 'title': 'Bird Box', 'year': '(2018)', 'rank': '29.', 'runtime': '124 min', 'rating': '6.6', 'votes': '305,135'}, {'movie_id': 'tt2798920', 'title': 'Annihilation', 'year': '(I) (2018)', 'rank': '30.', 'runtime': '115 min', 'rating': '6.8', 'votes': '298,808'}, {'movie_id': 'tt0448115', 'title': 'Shazam!', 'year': '(2019)', 'rank': '31.', 'runtime': '132 min', 'rating': '7.0', 'votes': '295,848'}, {'movie_id': 'tt4881806', 'title': 'Jurassic World: Fallen Kingdom', 'year': '(2018)', 'rank': '32.', 'runtime': '128 min', 'rating': '6.2', 'votes': '283,862'}, {'movie_id': 'tt8367814', 'title': 'The Gentlemen', 'year': '(2019)', 'rank': '33.', 'runtime': '113 min', 'rating': '7.8', 'votes': '282,900'}, {'movie_id': 'tt2948372', 'title': 'Soul', 'year': '(2020)', 'rank': '34.', 'runtime': '100 min', 'rating': '8.1', 'votes': '280,267'}, {'movie_id': 'tt7653254', 'title': 'Marriage Story', 'year': '(2019)', 'rank': '35.', 'runtime': '137 min', 'rating': '7.9', 'votes': '274,033'}, {'movie_id': 'tt7784604', 'title': 'Hereditary', 'year': '(2018)', 'rank': '36.', 'runtime': '127 min', 'rating': '7.3', 'votes': '270,157'}, {'movie_id': 'tt3606756', 'title': 'Incredibles 2', 'year': '(2018)', 'rank': '37.', 'runtime': '118 min', 'rating': '7.6', 'votes': '269,810'}, {'movie_id': 'tt6857112', 'title': 'Us', 'year': '(II) (2019)', 'rank': '38.', 'runtime': '116 min', 'rating': '6.8', 'votes': '257,673'}, {'movie_id': 'tt8772262', 'title': 'Midsommar', 'year': '(2019)', 'rank': '39.', 'runtime': '148 min', 'rating': '7.1', 'votes': '255,303'}, {'movie_id': 'tt0437086', 'title': 'Alita: Battle Angel', 'year': '(2019)', 'rank': '40.', 'runtime': '122 min', 'rating': '7.3', 'votes': '247,522'}, {'movie_id': 'tt5727208', 'title': 'Uncut Gems', 'year': '(2019)', 'rank': '41.', 'runtime': '135 min', 'rating': '7.4', 'votes': '246,741'}, {'movie_id': 'tt6139732', 'title': 'Aladdin', 'year': '(2019)', 'rank': '42.', 'runtime': '128 min', 'rating': '6.9', 'votes': '245,331'}, {'movie_id': 'tt7349662', 'title': 'BlacKkKlansman', 'year': '(2018)', 'rank': '43.', 'runtime': '135 min', 'rating': '7.5', 'votes': '242,325'}, {'movie_id': 'tt4123430', 'title': 'Fantastic Beasts: The Crimes of Grindelwald', 'year': '(2018)', 'rank': '44.', 'runtime': '134 min', 'rating': '6.5', 'votes': '239,448'}, {'movie_id': 'tt7126948', 'title': 'Wonder Woman 1984', 'year': '(2020)', 'rank': '45.', 'runtime': '151 min', 'rating': '5.4', 'votes': '232,962'}, {'movie_id': 'tt7349950', 'title': 'It Chapter Two', 'year': '(2019)', 'rank': '46.', 'runtime': '169 min', 'rating': '6.5', 'votes': '230,874'}, {'movie_id': 'tt6105098', 'title': 'The Lion King', 'year': '(2019)', 'rank': '47.', 'runtime': '118 min', 'rating': '6.8', 'votes': '226,997'}, {'movie_id': 'tt6823368', 'title': 'Glass', 'year': '(2019)', 'rank': '48.', 'runtime': '129 min', 'rating': '6.6', 'votes': '224,677'}, {'movie_id': 'tt1979376', 'title': 'Toy Story 4', 'year': '(2019)', 'rank': '49.', 'runtime': '100 min', 'rating': '7.7', 'votes': '223,650'}, {'movie_id': 'tt2704998', 'title': 'Game Night', 'year': '(I) (2018)', 'rank': '50.', 'runtime': '100 min', 'rating': '6.9', 'votes': '220,159'}]    \n",
    "    \"\"\"\n",
    "    url = \"http://www.imdb.com/search/title?at=0&sort=num_votes,desc&start=1&title_type=feature&year=2018,2020\"\n",
    "    print (\"Movies list: \", read_m_from_url(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_read_m_from_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "##  read_m_by_voting\n",
    "\n",
    "This method takes two years (first_year, last_year) and a number (top_number) as inputs. \n",
    "If we have first year = 2018, and last_year =2020, and top_number = 500, we want to retrieve top 500 movies \n",
    "that were released between 2018 and 2020, we need to do two things:\n",
    "\n",
    "##### 1. Construct a url. An example url can be \n",
    "    https://www.imdb.com/search/title/?at=0&sort=num_votes,desc&start=1&title_type=feature&year=2018,2020\n",
    "    \n",
    "        This URL means that the web page will display movies based on user_voting in descending \n",
    "        order \"sort=num_votes,desc\" between year 2018 and 2020,\n",
    "        It will start from the first movie (i.e., start=1 - we need to set the start index in the url).\n",
    "    \n",
    "        IMDB will display just 50 movies based on this URL. So in order to review more \n",
    "        movies, we need to click \"next\" on the web page. By clicking the next button,\n",
    "        we will see a new url\n",
    "           https://www.imdb.com/search/title/?at=0&sort=num_votes,desc&start=51&title_type=feature&year=2018,2020\n",
    "\n",
    "        If we compare the two urls above, we can easily see that in the second url, start=51, i.e., IMDB provides \n",
    "        another 50 movies, starting from movie No 51.If we want to retrieve the top 61 movies, we need to open \n",
    "        two web pages with two urls. \n",
    "        And if we want to retrieve top 256 movies, we need to open 6 different URLs.\n",
    "        Obviously, we want to use a loop to construct the different URLs.\n",
    "    \n",
    "    \n",
    "##### 2. Read movies from the URL: using \"read_m_from_url\" method. \n",
    "      What this method does is that it opens a url and read numbers_of_movies_you_need_to_read_on_the_page. \n",
    "      For example, if we want to read top 61 movies, we will need to first open \n",
    "      a url https://www.imdb.com/search/title/?at=0&sort=num_votes,desc&start=1&title_type=feature&year=2018,2020\n",
    "      \n",
    "      We need to read all 50 movies on the page by calling read_m_from_url(url), and then we need to open \n",
    "      the second url http://www.imdb.com/search/title?at=0&sort=user_rating&start=1&title_type=feature&year=2005,2016, but \n",
    "      we just need to read 61-50=11 movies from the page. Now, let's set current_index = 51 and top_number = 61, we \n",
    "      actually need to retrieve (top_number - current_index + 1) movies. we can do this by calling\n",
    "      read_m_from_url(url, top_number - the current_index+1).\n",
    "      \n",
    "      Hence, we need to use if statement here. Based on top_number, we may need to open multiple urls \n",
    "         (e.g., if top 256, we need to open 6 urls)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_per_page = 50 # by default, imdb return 50 movies page url.\n",
    "def read_m_by_voting(first_year, last_year, top_number):\n",
    "    \n",
    "    current_index = 1  # initialize current_index. In the first iteration, we need to have start = 1.\n",
    "    \n",
    "    final_list = []  # initialize the return value. This method returns a list. Each item in the list is a dictionary. \n",
    "                     # Each dictionary includes information regarding a movie.\n",
    "\n",
    "    for i in range(int(math.ceil(top_number/50.0))):\n",
    "        url= 'http://www.imdb.com/search/title/?at=0&sort=num_votes,desc&start='+str(current_index)+'&title_type=feature&year='+str(first_year)+','+ str(last_year)\n",
    "\n",
    "        if (i+1) == len(range( int(math.ceil(top_number/50.0)))):\n",
    "            lis = read_m_from_url(url, top_number - current_index + 1)\n",
    "        else:\n",
    "            lis = read_m_from_url(url, m_per_page)\n",
    "        final_list += lis\n",
    "        current_index +=50\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test read_m_by_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_m_by_voting():\n",
    "    \"\"\"output:\n",
    "    [{'movie_id': 'tt7286456', 'title': 'Joker', 'year': '(2019)', 'rank': '1.', 'genres': 'Crime, Drama, Thriller', 'runtime': '122 min', 'rating': '8.4', 'votes': '\"1,074,179\"'}, {'movie_id': 'tt4154796', 'title': 'Avengers: Endgame', 'year': '(2019)', 'rank': '2.', 'genres': 'Action, Adventure, Drama', 'runtime': '181 min', 'rating': '8.4', 'votes': '\"945,422\"'}]\n",
    "    \"\"\"\n",
    "    print (read_m_by_voting(2018,2020,3)) # This will print a list of top three movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  test_read_m_by_voting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# write_movies_csv\n",
    "This method to write the movies to a csv file.\n",
    "Each row in the csv file represents a movie. \n",
    " - The parameter final_list includes a number of movies, which is the output of the function read_m_by_voting. \n",
    " - The filename represents the output file name.\n",
    " \n",
    " ***\n",
    " Important note:  make sure to complete the code of read_m_from_url method before running write_movies_csv method.\n",
    " ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_movies_csv(final_list, filename):\n",
    "\n",
    "    lis = [] # to write the file, we create a list of strings.\n",
    "    \n",
    "    header = \"movie_id,\"+\"rank,\"+\"title,\"+\"year,\"+\"rating,\"+\"runtime,\" +\"votes\"\n",
    "    lis.append(header) # add the header to the list\n",
    "    for movie in final_list:\n",
    "        string =  process_str_with_comma(movie[\"movie_id\"]) +\",\" + process_str_with_comma(movie[\"rank\"]) +\",\"+ process_str_with_comma(movie[\"title\"]) +\",\"+ process_str_with_comma(movie[\"year\"]) + \",\"+  process_str_with_comma(movie[\"rating\"]) +\",\"+ process_str_with_comma(movie[\"runtime\"]) + \",\" + process_str_with_comma(movie[\"votes\"])\n",
    "        print (string)\n",
    "        lis.append(string)# add the string to the list\n",
    "\n",
    "    # Writing the strings list to csv file\n",
    "    f = None\n",
    "    f = open(filename,\"w\")\n",
    "    for s in lis:\n",
    "        f.write(\"%s\\n\" % s)\n",
    "    f.close()\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output of the test_write_movies_csv method is the \"IMDb_TopVoted.csv\" file.\n",
    "def test_write_movies_csv(): \n",
    "    li = read_m_by_voting(2018, 2020, 500) # To read the top voted 500 movies between 2018 and 2020 from imdb.\n",
    "    print(li)\n",
    "    print(\"================================================================\")\n",
    "    write_movies_csv(li,\"IMDb_TopVoted.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_write_movies_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the given dataset \"Movies.csv\" to Pandas DataFrame called df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  Your code here ...    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the scraped data from the IMDb_TopVoted.csv file to Pandas DataFrame called df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You need to import the collected dataset \"IMDb_TopVoted.csv\".\n",
    "# To handel Latin characters that may contained in the csv file\n",
    "# with no issue, use  encoding= \"ISO-8859-1\" with the pd.read_csv()\n",
    "# Example: df1 = pd.read_csv('thefilename.csv', encoding= \"ISO-8859-1\") \n",
    "# Using encoding= \"ISO-8859-1\" will avoid Unicode-Decode-Errors.\n",
    "\n",
    "'''  Your code here ...    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleansing and transformation to convert the columns datatype for df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and tranforming df2\n",
    " # rank, year, runtime, and votes should have a numeric integer data type.\n",
    "\n",
    "'''  Your code here ...    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \tEnrich the given dataset (df1) by merging it to the scraped data (df2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merege the two dataframes to one dataframe called df.\n",
    "'''  Your code here ...    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange the dataset fields to be listed in the following order: \n",
    " movie_id, rank, votes, title, originalTitle, year, rating, titleType, isAdult, runtime,  genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the dataset fields.\n",
    "'''  Your code here ...    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the enriched dataset to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following naming convention: \n",
    "#  Project_3_PartA_Lastname.csv\n",
    "\n",
    "'''  Your code here ...    '''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
